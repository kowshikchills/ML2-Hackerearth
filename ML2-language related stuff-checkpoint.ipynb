{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "df_train1 = pd.read_csv(\"train2.csv\")\n",
    "df_test1 = pd.read_csv(\"test2.csv\")\n",
    "del df_train1['Unnamed: 0']\n",
    "del df_test1['Unnamed: 0']\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "df_train = df_train1[:]\n",
    "df_test = df_test1[:]\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "cols_to_use = ['name','desc']\n",
    "len_feats = ['name_len','desc_len']\n",
    "count_feats = ['name_count','desc_count']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    df_train[len_feats[i]] = df_train[cols_to_use[i]].apply(str).apply(len)\n",
    "    df_train[count_feats[i]] = df_train[cols_to_use[i]].apply(str).apply(lambda x: len(x.split(' ')))\n",
    "    \n",
    "    \n",
    "for i in np.arange(2):\n",
    "    df_test[len_feats[i]] = df_test[cols_to_use[i]].apply(str).apply(len)\n",
    "    df_test[count_feats[i]] = df_test[cols_to_use[i]].apply(str).apply(lambda x: len(x.split(' ')))\n",
    "    \n",
    "    \n",
    "    \n",
    "#Flag 1 based on goal\n",
    "thre = 700000\n",
    "df_test_decided_1  = df_test[df_test.goal>=thre]\n",
    "df_test_1  = df_test[df_test.goal<thre]\n",
    "df_train_decided_1  = df_train[df_train.goal>=thre]\n",
    "df_train_1  = df_train[df_train.goal<thre]\n",
    "\n",
    "df_test_decided_1['final_status'] = 0\n",
    "\n",
    "#Flag 2 based on disable_communication\n",
    "\n",
    "df_test_decided_2  = df_test_1[df_test_1.disable_communication ==1 ]\n",
    "df_test_2  = df_test_1[df_test_1.disable_communication !=1]\n",
    "df_train_decided_2  = df_train_1[df_train_1.disable_communication ==1 ]\n",
    "df_train_2  = df_train_1[df_train_1.disable_communication !=1]\n",
    "\n",
    "df_test_decided_2['final_status'] = 0\n",
    "\n",
    "for df in [df_test_decided_2,df_test_2,df_train_decided_2,df_train_2]:\n",
    "    del df['disable_communication']\n",
    "    \n",
    "\n",
    "#Flag 2 based on   deadline-state_changed_at\n",
    "\n",
    "df_test_decided_3  = df_test_2[df_test_2['deadline-state_changed_at'].values<0]\n",
    "df_test_3  = df_test_2[df_test_2['deadline-state_changed_at'].values>=0]\n",
    "df_train_decided_3  = df_train_2[df_train_2['deadline-state_changed_at'].values<0]\n",
    "df_train_3  = df_train_2[df_train_2['deadline-state_changed_at'].values>=0]\n",
    "\n",
    "df_test_decided_3['final_status'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "desc= []\n",
    "for i in df_train_3['desc'].values:\n",
    "    if str(i) == 'nan':\n",
    "        i = 'none'\n",
    "        b = TextBlob(i)\n",
    "        x = b.sentiment\n",
    "        polarity.append(x.polarity)\n",
    "        subjectivity.append(x.subjectivity)\n",
    "        desc.append(i)\n",
    "    else:\n",
    "        i = i.decode('utf8').encode('ascii', errors='ignore')\n",
    "        b = TextBlob(i)\n",
    "        x = b.sentiment\n",
    "        polarity.append(x.polarity)\n",
    "        subjectivity.append(x.subjectivity)\n",
    "        desc.append(i)\n",
    "        \n",
    "df_train_3['polarity'] =polarity\n",
    "df_train_3['subjectivity'] =subjectivity\n",
    "df_train_3['desc'] = desc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from textblob import TextBlob\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "desc= []\n",
    "for i in df_test_3['desc'].values:\n",
    "    if str(i) == 'nan':\n",
    "        i = 'nothing much'\n",
    "        b = TextBlob(i)\n",
    "        x = b.sentiment\n",
    "        polarity.append(x.polarity)\n",
    "        subjectivity.append(x.subjectivity)\n",
    "        desc.append(i)\n",
    "    else:\n",
    "        i = i.decode('utf8').encode('ascii', errors='ignore')\n",
    "        b = TextBlob(i)\n",
    "        x = b.sentiment\n",
    "        polarity.append(x.polarity)\n",
    "        subjectivity.append(x.subjectivity)\n",
    "        desc.append(i)\n",
    "df_test_3['polarity'] =polarity\n",
    "df_test_3['subjectivity'] =subjectivity\n",
    "df_test_3['desc'] = desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df_train_3['desc'].values)\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n",
    "\n",
    "Y = df_train_3['final_status'].values\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = MultinomialNB().fit(X_train_tfidf[:int(len(Y)*0.75)], Y[:int(len(Y)*0.75)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14130  3118]\n",
      " [ 4785  3439]]\n",
      "0.618695879926\n",
      "0.465327109127\n"
     ]
    }
   ],
   "source": [
    "x = clf.predict_proba(X_train_tfidf[int(len(Y)*0.75):]).T[1]\n",
    "pred = x>0.3\n",
    "pred = pred*1\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,f1_score\n",
    "\n",
    "print confusion_matrix(pred, Y[int(len(Y)*0.75):])\n",
    "print roc_auc_score(pred,Y[int(len(Y)*0.75):])\n",
    "print f1_score(pred,Y[int(len(Y)*0.75):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df_train_3['keywords'].values)\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n",
    "\n",
    "Y = df_train_3['final_status'].values\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = MultinomialNB().fit(X_train_tfidf[:int(len(Y)*0.75)], Y[:int(len(Y)*0.75)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13861  3889]\n",
      " [ 5054  2668]]\n",
      "0.563203876979\n",
      "0.373695636949\n"
     ]
    }
   ],
   "source": [
    "x = clf.predict_proba(X_train_tfidf[int(len(Y)*0.75):]).T[1]\n",
    "pred = x>0.38\n",
    "pred = pred*1\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,f1_score\n",
    "print confusion_matrix(pred, Y[int(len(Y)*0.75):])\n",
    "print roc_auc_score(pred,Y[int(len(Y)*0.75):])\n",
    "print f1_score(pred,Y[int(len(Y)*0.75):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting xgboost',\n",
       " '  Downloading xgboost-0.6a2.tar.gz (1.2MB)',\n",
       " 'No files/directories in c:\\\\users\\\\c5067944\\\\appdata\\\\local\\\\temp\\\\pip-build-nv8re2\\\\xgboost\\\\pip-egg-info (from PKG-INFO)']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
